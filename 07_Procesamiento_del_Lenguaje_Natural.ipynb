{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_Procesamiento_del_Lenguaje_Natural.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOlSqbAXF3sASOIzgh/4IB9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IEXE-Tec/aprendizaje-maquina-2/blob/master/07_Procesamiento_del_Lenguaje_Natural.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kECscepGtsRT"
      },
      "source": [
        "Installing pycaret library:\n",
        "+ https://towardsdatascience.com/announcing-pycaret-2-0-39c11014540e \n",
        "+ https://pycaret.org/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_4YZ-A-ty8L"
      },
      "source": [
        "!pip install pycaret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUw9jGQ6e8zi",
        "outputId": "d7685e23-942c-4553-9c24-437803260179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "from pycaret.utils import version\n",
        "version()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.1.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i2Pou3JHZ4l"
      },
      "source": [
        "import nltk\n",
        "import pycaret"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB2bZLB4umXm"
      },
      "source": [
        "# Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPdVrOSDup0Q"
      },
      "source": [
        "## I. Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBGITeID1qQL"
      },
      "source": [
        "# importar el modulo de tokenizacion de nltk\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWoV0d8x2qAF",
        "outputId": "7b61f488-5e0e-430a-a921-5ee1e77d785f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "example_text = \"Esto es un ejemplo. O noooo?\"\n",
        "print(sent_tokenize(example_text))\n",
        "print(word_tokenize(example_text))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Esto es un ejemplo.', 'O noooo?']\n",
            "['Esto', 'es', 'un', 'ejemplo', '.', 'O', 'noooo', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dSxot7HuuWo",
        "outputId": "601e795f-f906-478a-8e73-4b0abbd2cf91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "# Texto de ejemplo. Ene ste caso usamos las tres comillas para separar\n",
        "# el texto en varias lineas dentro de nuestro codigo.\n",
        "example_text = ''' Hola mi nombre es Mario. Mi cuenta de github\n",
        "es uumami. Estas listo para convertirte en un experto de NLP.\n",
        "Ezta horacion contiene muchos erroress gramaticales.\n",
        "'''\n",
        "print(example_text)\n",
        "print(sent_tokenize(example_text))\n",
        "print(word_tokenize(example_text))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Hola mi nombre es Mario. Mi cuenta de github\n",
            "es uumami. Estas listo para convertirte en un experto de NLP.\n",
            "Ezta horacion contiene muchos erroress gramaticales.\n",
            "\n",
            "[' Hola mi nombre es Mario.', 'Mi cuenta de github\\nes uumami.', 'Estas listo para convertirte en un experto de NLP.', 'Ezta horacion contiene muchos erroress gramaticales.']\n",
            "['Hola', 'mi', 'nombre', 'es', 'Mario', '.', 'Mi', 'cuenta', 'de', 'github', 'es', 'uumami', '.', 'Estas', 'listo', 'para', 'convertirte', 'en', 'un', 'experto', 'de', 'NLP', '.', 'Ezta', 'horacion', 'contiene', 'muchos', 'erroress', 'gramaticales', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tj0dRqdGOSf"
      },
      "source": [
        "texto = word_tokenize(example_text)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzxM8D-HEvA-"
      },
      "source": [
        "## III. Stemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqzc2xAj8uyt"
      },
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "stemmer = SnowballStemmer('spanish')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0srEErAF0Nv",
        "outputId": "f71ddb69-a51d-49f5-fd3b-ca99b40adba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        }
      },
      "source": [
        "stemmed_text = [stemmer.stem(i) for i in texto]\n",
        "stemmed_text"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hol',\n",
              " 'mi',\n",
              " 'nombr',\n",
              " 'es',\n",
              " 'mari',\n",
              " '.',\n",
              " 'mi',\n",
              " 'cuent',\n",
              " 'de',\n",
              " 'github',\n",
              " 'es',\n",
              " 'uumami',\n",
              " '.',\n",
              " 'estas',\n",
              " 'list',\n",
              " 'par',\n",
              " 'convertirt',\n",
              " 'en',\n",
              " 'un',\n",
              " 'expert',\n",
              " 'de',\n",
              " 'nlp',\n",
              " '.',\n",
              " 'ezta',\n",
              " 'horacion',\n",
              " 'contien',\n",
              " 'much',\n",
              " 'erroress',\n",
              " 'gramatical',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    }
  ]
}