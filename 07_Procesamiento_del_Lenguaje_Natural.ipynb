{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_Procesamiento_del_Lenguaje_Natural.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPt3PAMCNRKuqLH2rdqeFYw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IEXE-Tec/aprendizaje-maquina-2/blob/master/07_Procesamiento_del_Lenguaje_Natural.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kECscepGtsRT"
      },
      "source": [
        "Installing pycaret library:\n",
        "+ https://towardsdatascience.com/announcing-pycaret-2-0-39c11014540e \n",
        "+ https://pycaret.org/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_4YZ-A-ty8L",
        "outputId": "0b25397c-6e69-4aaa-9a13-9fac04e06b8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install pycaret"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycaret in /usr/local/lib/python3.6/dist-packages (2.2)\n",
            "Requirement already satisfied: lightgbm>=2.3.1 in /usr/local/lib/python3.6/dist-packages (from pycaret) (3.0.0)\n",
            "Requirement already satisfied: plotly>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from pycaret) (4.4.1)\n",
            "Requirement already satisfied: kmodes>=0.10.1 in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.10.2)\n",
            "Requirement already satisfied: imbalanced-learn>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.7.0)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.15.3)\n",
            "Requirement already satisfied: cufflinks>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.17.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.17.0)\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.6/dist-packages (from pycaret) (2.1.2)\n",
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.11.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from pycaret) (2.2.4)\n",
            "Requirement already satisfied: pyod in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.8.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from pycaret) (3.2.5)\n",
            "Requirement already satisfied: yellowbrick>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.2)\n",
            "Requirement already satisfied: scikit-learn>=0.23.2 in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.23.2)\n",
            "Requirement already satisfied: xgboost>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.2.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from pycaret) (3.6.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.11.0)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.4.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from pycaret) (7.5.1)\n",
            "Requirement already satisfied: catboost>=0.23.2 in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.24.2)\n",
            "Requirement already satisfied: scikit-plot in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.3.7)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.6/dist-packages (from pycaret) (5.5.0)\n",
            "Requirement already satisfied: pandas-profiling>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from pycaret) (2.9.0)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from pycaret) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.1.3)\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.14.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm>=2.3.1->pycaret) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly>=4.4.1->pycaret) (1.15.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.4.1->pycaret) (1.3.3)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from cufflinks>=0.17.0->pycaret) (0.3.0)\n",
            "Requirement already satisfied: setuptools>=34.4.1 in /usr/local/lib/python3.6/dist-packages (from cufflinks>=0.17.0->pycaret) (50.3.0)\n",
            "Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (0.35.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (3.6.4)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (1.15)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (0.16.0)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (2.11.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (2.7.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (3.13)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (7.1.2)\n",
            "Requirement already satisfied: databricks-cli>=0.8.7 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (3.12.4)\n",
            "Requirement already satisfied: prometheus-flask-exporter in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (0.18.1)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (0.4.1)\n",
            "Requirement already satisfied: querystring-parser in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.2.4)\n",
            "Requirement already satisfied: gorilla in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (0.3.0)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.1.2)\n",
            "Requirement already satisfied: docker>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (4.3.1)\n",
            "Requirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (2.8.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.3.0)\n",
            "Requirement already satisfied: gunicorn; platform_system != \"Windows\" in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (20.0.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (0.3)\n",
            "Requirement already satisfied: alembic<=1.4.1 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.4.1)\n",
            "Requirement already satisfied: gitpython>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (3.1.11)\n",
            "Requirement already satisfied: sqlalchemy<=1.3.13 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.3.13)\n",
            "Requirement already satisfied: azure-storage-blob>=12.0 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (12.5.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (0.8.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (2.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (3.0.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from pyod->pycaret) (0.10.2)\n",
            "Requirement already satisfied: suod in /usr/local/lib/python3.6/dist-packages (from pyod->pycaret) (0.0.4)\n",
            "Requirement already satisfied: numba>=0.35 in /usr/local/lib/python3.6/dist-packages (from pyod->pycaret) (0.48.0)\n",
            "Requirement already satisfied: combo in /usr/local/lib/python3.6/dist-packages (from pyod->pycaret) (0.1.1)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.6/dist-packages (from yellowbrick>=1.0.1->pycaret) (0.10.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.23.2->pycaret) (2.1.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->pycaret) (3.0.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (4.3.3)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (4.10.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (5.0.8)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (3.5.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost>=0.23.2->pycaret) (0.10.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (1.0.18)\n",
            "Requirement already satisfied: visions[type_image_path]==0.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.5.0)\n",
            "Requirement already satisfied: tangled-up-in-unicode>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.0.6)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (20.2.0)\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.4.2)\n",
            "Requirement already satisfied: phik>=0.9.10 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.10.0)\n",
            "Requirement already satisfied: htmlmin>=0.1.12 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.1.12)\n",
            "Requirement already satisfied: confuse>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (1.3.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud->pycaret) (7.0.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pycaret) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pycaret) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pycaret) (2018.9)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (8.5.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (1.9.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (1.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (0.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.7.2->pyLDAvis->pycaret) (1.1.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from databricks-cli>=0.8.7->mlflow->pycaret) (0.8.7)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.6/dist-packages (from prometheus-flask-exporter->mlflow->pycaret) (0.8.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow->pycaret) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow->pycaret) (1.1.0)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.6/dist-packages (from docker>=4.0.0->mlflow->pycaret) (0.57.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow->pycaret) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow->pycaret) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow->pycaret) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow->pycaret) (1.24.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.6/dist-packages (from alembic<=1.4.1->mlflow->pycaret) (1.1.3)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.6/dist-packages (from alembic<=1.4.1->mlflow->pycaret) (1.0.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from gitpython>=2.1.0->mlflow->pycaret) (4.0.5)\n",
            "Requirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from azure-storage-blob>=12.0->mlflow->pycaret) (3.2.1)\n",
            "Requirement already satisfied: azure-core<2.0.0,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from azure-storage-blob>=12.0->mlflow->pycaret) (1.8.2)\n",
            "Requirement already satisfied: msrest>=0.6.10 in /usr/local/lib/python3.6/dist-packages (from azure-storage-blob>=12.0->mlflow->pycaret) (0.6.19)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->pycaret) (2.0.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels->pyod->pycaret) (0.5.1)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.35->pyod->pycaret) (0.31.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets->pycaret) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.1.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (4.6.3)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython->pycaret) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->pycaret) (0.2.5)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.6/dist-packages (from visions[type_image_path]==0.5.0->pandas-profiling>=2.8.0->pycaret) (2.5)\n",
            "Requirement already satisfied: imagehash; extra == \"type_image_path\" in /usr/local/lib/python3.6/dist-packages (from visions[type_image_path]==0.5.0->pandas-profiling>=2.8.0->pycaret) (4.1.0)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow->pycaret) (3.0.4)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.1.4->azure-storage-blob>=12.0->mlflow->pycaret) (1.14.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.6.10->azure-storage-blob>=12.0->mlflow->pycaret) (1.3.0)\n",
            "Requirement already satisfied: isodate>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.6.10->azure-storage-blob>=12.0->mlflow->pycaret) (0.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->pycaret) (3.3.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->pycaret) (19.0.2)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.5.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.9.1)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.6/dist-packages (from imagehash; extra == \"type_image_path\"->visions[type_image_path]==0.5.0->pandas-profiling>=2.8.0->pycaret) (1.1.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.1.4->azure-storage-blob>=12.0->mlflow->pycaret) (2.20)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.10->azure-storage-blob>=12.0->mlflow->pycaret) (3.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (3.2.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.4.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.4.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (20.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUw9jGQ6e8zi",
        "outputId": "c1837615-7162-46f5-ccd1-5f444b79450a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "from pycaret.utils import version\n",
        "version()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA99ILJFHqa3"
      },
      "source": [
        "Installing Autocorrect:\n",
        "+ https://github.com/phatpiglet/autocorrect\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX_UZpHaHtYN",
        "outputId": "e8e04028-b8e7-4040-f5ad-13b0c7e2b4a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pip install autocorrect"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: autocorrect in /usr/local/lib/python3.6/dist-packages (2.2.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i2Pou3JHZ4l"
      },
      "source": [
        "import nltk\n",
        "import pycaret"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB2bZLB4umXm"
      },
      "source": [
        "# Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPdVrOSDup0Q"
      },
      "source": [
        "## I. Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBGITeID1qQL",
        "outputId": "7c057c31-4990-4e7b-e450-ee8dc75a90fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# importar el modulo de tokenizacion de nltk\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWoV0d8x2qAF",
        "outputId": "44ea8765-3135-4a37-9af9-51977511676d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "example_text = \"Esto es un ejemplo. O noooo?\"\n",
        "print(sent_tokenize(example_text))\n",
        "print(word_tokenize(example_text))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Esto es un ejemplo.', 'O noooo?']\n",
            "['Esto', 'es', 'un', 'ejemplo', '.', 'O', 'noooo', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dSxot7HuuWo",
        "outputId": "1c6d57d2-dcd6-4405-ef60-82378c88070d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "# Texto de ejemplo. Ene ste caso usamos las tres comillas para separar\n",
        "# el texto en varias lineas dentro de nuestro codigo.\n",
        "example_text = ''' Hola mi nombre es Mario. Mi cuenta de github\n",
        "es uumami. Estas listo para convertirte en un experto de NLP.\n",
        "Ezta horacion contiene muchos erroress gramaticales.\n",
        "'''\n",
        "print(example_text)\n",
        "print(sent_tokenize(example_text))\n",
        "print(word_tokenize(example_text))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Hola mi nombre es Mario. Mi cuenta de github\n",
            "es uumami. Estas listo para convertirte en un experto de NLP.\n",
            "Ezta horacion contiene muchos erroress gramaticales.\n",
            "\n",
            "[' Hola mi nombre es Mario.', 'Mi cuenta de github\\nes uumami.', 'Estas listo para convertirte en un experto de NLP.', 'Ezta horacion contiene muchos erroress gramaticales.']\n",
            "['Hola', 'mi', 'nombre', 'es', 'Mario', '.', 'Mi', 'cuenta', 'de', 'github', 'es', 'uumami', '.', 'Estas', 'listo', 'para', 'convertirte', 'en', 'un', 'experto', 'de', 'NLP', '.', 'Ezta', 'horacion', 'contiene', 'muchos', 'erroress', 'gramaticales', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tj0dRqdGOSf"
      },
      "source": [
        "texto = word_tokenize(example_text)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBTNkxBxIa5o"
      },
      "source": [
        "# II. Spell check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lxqzZ_oRs2_"
      },
      "source": [
        "from autocorrect import Speller"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_Yb6k0GIfi4"
      },
      "source": [
        "spell = Speller(lang='es')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if_n9aZ8Iitl",
        "outputId": "f6d437e0-e127-4275-9958-d91adf0151b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        }
      },
      "source": [
        "corrected_text = [spell(i) for i in texto]\n",
        "corrected_text"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hola',\n",
              " 'mi',\n",
              " 'nombre',\n",
              " 'es',\n",
              " 'Mario',\n",
              " '.',\n",
              " 'Mi',\n",
              " 'cuenta',\n",
              " 'de',\n",
              " 'github',\n",
              " 'es',\n",
              " 'umami',\n",
              " '.',\n",
              " 'Estas',\n",
              " 'listo',\n",
              " 'para',\n",
              " 'convertirte',\n",
              " 'en',\n",
              " 'un',\n",
              " 'experto',\n",
              " 'de',\n",
              " 'LP',\n",
              " '.',\n",
              " 'Esta',\n",
              " 'horacio',\n",
              " 'contiene',\n",
              " 'muchos',\n",
              " 'errores',\n",
              " 'gramaticales',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVw9RFFEP9l-"
      },
      "source": [
        "## III. Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZAzvIOnRmYG",
        "outputId": "177ba50c-c3b1-4b1d-a132-803f59378d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjjDE2POQ2H8",
        "outputId": "213057b0-c0fc-426b-966c-729022ef01df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "stopwords_en = stopwords.words('english')\n",
        "\n",
        "counter = 0\n",
        "for w in stopwords_en:\n",
        "  print(w, end=', ')\n",
        "  counter += 1\n",
        "  if (counter%10)== 0:\n",
        "    print()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i, me, my, myself, we, our, ours, ourselves, you, you're, \n",
            "you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, \n",
            "himself, she, she's, her, hers, herself, it, it's, its, itself, \n",
            "they, them, their, theirs, themselves, what, which, who, whom, this, \n",
            "that, that'll, these, those, am, is, are, was, were, be, \n",
            "been, being, have, has, had, having, do, does, did, doing, \n",
            "a, an, the, and, but, if, or, because, as, until, \n",
            "while, of, at, by, for, with, about, against, between, into, \n",
            "through, during, before, after, above, below, to, from, up, down, \n",
            "in, out, on, off, over, under, again, further, then, once, \n",
            "here, there, when, where, why, how, all, any, both, each, \n",
            "few, more, most, other, some, such, no, nor, not, only, \n",
            "own, same, so, than, too, very, s, t, can, will, \n",
            "just, don, don't, should, should've, now, d, ll, m, o, \n",
            "re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, \n",
            "doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, \n",
            "ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, \n",
            "shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't, "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc2il63oQB4q",
        "outputId": "6a7332c7-e0a5-4e63-ad92-8aaf90ce0438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        }
      },
      "source": [
        "stopwords_es = stopwords.words('spanish')\n",
        "\n",
        "counter = 0\n",
        "for w in stopwords_es:\n",
        "  print(w, end=', ')\n",
        "  counter += 1\n",
        "  if (counter%10)== 0:\n",
        "    print()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "de, la, que, el, en, y, a, los, del, se, \n",
            "las, por, un, para, con, no, una, su, al, lo, \n",
            "como, más, pero, sus, le, ya, o, este, sí, porque, \n",
            "esta, entre, cuando, muy, sin, sobre, también, me, hasta, hay, \n",
            "donde, quien, desde, todo, nos, durante, todos, uno, les, ni, \n",
            "contra, otros, ese, eso, ante, ellos, e, esto, mí, antes, \n",
            "algunos, qué, unos, yo, otro, otras, otra, él, tanto, esa, \n",
            "estos, mucho, quienes, nada, muchos, cual, poco, ella, estar, estas, \n",
            "algunas, algo, nosotros, mi, mis, tú, te, ti, tu, tus, \n",
            "ellas, nosotras, vosotros, vosotras, os, mío, mía, míos, mías, tuyo, \n",
            "tuya, tuyos, tuyas, suyo, suya, suyos, suyas, nuestro, nuestra, nuestros, \n",
            "nuestras, vuestro, vuestra, vuestros, vuestras, esos, esas, estoy, estás, está, \n",
            "estamos, estáis, están, esté, estés, estemos, estéis, estén, estaré, estarás, \n",
            "estará, estaremos, estaréis, estarán, estaría, estarías, estaríamos, estaríais, estarían, estaba, \n",
            "estabas, estábamos, estabais, estaban, estuve, estuviste, estuvo, estuvimos, estuvisteis, estuvieron, \n",
            "estuviera, estuvieras, estuviéramos, estuvierais, estuvieran, estuviese, estuvieses, estuviésemos, estuvieseis, estuviesen, \n",
            "estando, estado, estada, estados, estadas, estad, he, has, ha, hemos, \n",
            "habéis, han, haya, hayas, hayamos, hayáis, hayan, habré, habrás, habrá, \n",
            "habremos, habréis, habrán, habría, habrías, habríamos, habríais, habrían, había, habías, \n",
            "habíamos, habíais, habían, hube, hubiste, hubo, hubimos, hubisteis, hubieron, hubiera, \n",
            "hubieras, hubiéramos, hubierais, hubieran, hubiese, hubieses, hubiésemos, hubieseis, hubiesen, habiendo, \n",
            "habido, habida, habidos, habidas, soy, eres, es, somos, sois, son, \n",
            "sea, seas, seamos, seáis, sean, seré, serás, será, seremos, seréis, \n",
            "serán, sería, serías, seríamos, seríais, serían, era, eras, éramos, erais, \n",
            "eran, fui, fuiste, fue, fuimos, fuisteis, fueron, fuera, fueras, fuéramos, \n",
            "fuerais, fueran, fuese, fueses, fuésemos, fueseis, fuesen, sintiendo, sentido, sentida, \n",
            "sentidos, sentidas, siente, sentid, tengo, tienes, tiene, tenemos, tenéis, tienen, \n",
            "tenga, tengas, tengamos, tengáis, tengan, tendré, tendrás, tendrá, tendremos, tendréis, \n",
            "tendrán, tendría, tendrías, tendríamos, tendríais, tendrían, tenía, tenías, teníamos, teníais, \n",
            "tenían, tuve, tuviste, tuvo, tuvimos, tuvisteis, tuvieron, tuviera, tuvieras, tuviéramos, \n",
            "tuvierais, tuvieran, tuviese, tuvieses, tuviésemos, tuvieseis, tuviesen, teniendo, tenido, tenida, \n",
            "tenidos, tenidas, tened, "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kw4_Nz3UmJm"
      },
      "source": [
        "def print_text(texx = [], module=10, sep=' '):\n",
        "  counter = 0\n",
        "  for w in texx:\n",
        "    print(w, end=sep)\n",
        "    counter += 1\n",
        "    if (counter % module)== 0:\n",
        "      print()\n",
        "  print('\\n ------- Tamano del texto: ', len(texx))\n",
        "  print()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITCTj4EFULL-",
        "outputId": "1e919327-89a4-457d-c85d-2e8216fcdd82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "# Removamos las stopwords de nuestro texto\n",
        "print('\\n Texto corregido:')\n",
        "print_text(corrected_text, module=11)\n",
        "\n",
        "short_text = [w for w in corrected_text if w not in stopwords_es]\n",
        "print('\\n Texto sin stopwords:')\n",
        "print_text(short_text, module=11)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Texto corregido:\n",
            "Hola mi nombre es Mario . Mi cuenta de github es \n",
            "umami . Estas listo para convertirte en un experto de LP \n",
            ". Esta horacio contiene muchos errores gramaticales . \n",
            " ------- Tamano del texto:  30\n",
            "\n",
            "\n",
            " Texto sin stopwords:\n",
            "Hola nombre Mario . Mi cuenta github umami . Estas listo \n",
            "convertirte experto LP . Esta horacio contiene errores gramaticales . \n",
            " ------- Tamano del texto:  21\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzxM8D-HEvA-"
      },
      "source": [
        "## IV. Stemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqzc2xAj8uyt"
      },
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "stemmer = SnowballStemmer('spanish')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNd5c-nyMJ1W",
        "outputId": "c175e6ee-b84d-4729-9db2-be0031ef3ed3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "[stemmer.stem(i) for i in ['corriendo', 'correr', 'corremos',\n",
        "                           'corriamos','corrian', \n",
        "                           'correlacion', 'correlacionado']]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['corr', 'corr', 'corr', 'corri', 'corri', 'correlacion', 'correlacion']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0srEErAF0Nv",
        "outputId": "ff2a7cbf-3653-4f9d-f802-8fe756f0750d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "stemmed_text = [stemmer.stem(i) for i in corrected_text]\n",
        "print_text(stemmed_text, module=11)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hol mi nombr es mari . mi cuent de github es \n",
            "umami . estas list par convertirt en un expert de lp \n",
            ". esta horaci contien much error gramatical . \n",
            " ------- Tamano del texto:  30\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVDE_3X7p5wQ"
      },
      "source": [
        "## V. Lemmatizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0fWcC8hrXkl"
      },
      "source": [
        "Dado que el texto que estamos anlizaando se encuenntra en espanol, es necesario buscar una funcion disenyada para nuestra lengua.  \n",
        "En este nos puede ayudar spacy.  \n",
        "+ spacy: https://spacy.io/usage \n",
        "+ spanish lemmatizer: https://spacy.io/models/es#es_core_news_sm "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYa1_Y_HuoXa",
        "outputId": "a825d337-2787-4998-ae21-7a5bcff37ef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "source": [
        "!python3 -m spacy download es_core_news_sm"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: es_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.2.5/es_core_news_sm-2.2.5.tar.gz#egg=es_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from es_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.3.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_K-usVxvVhY"
      },
      "source": [
        "# Importar spacy y el lemmatizer en espanyol\n",
        "import spacy\n",
        "import es_core_news_sm\n",
        "nlp = es_core_news_sm.load()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiKoAF0p1RyP",
        "outputId": "b4710366-a812-44c4-890f-555109681658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "ex_lem = \"Hola estoy aprendiendo a utilizar inteligencia artificial. \\n\"\n",
        "print(ex_lem)\n",
        "ex_lem = word_tokenize(ex_lem)\n",
        "for w in ex_lem:\n",
        "  doc = nlp(w)\n",
        "  for word in doc:\n",
        "    print(word.text, \"=>\", word.lemma_)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hola estoy aprendiendo a utilizar inteligencia artificial. \n",
            "\n",
            "Hola => Hola\n",
            "estoy => estar\n",
            "aprendiendo => aprender\n",
            "a => a\n",
            "utilizar => utilizar\n",
            "inteligencia => inteligencia\n",
            "artificial => artificial\n",
            ". => .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzoQIpJc_o_W"
      },
      "source": [
        "Creemos una funcion que lemamtize un texto que ya este separado en tokens (tokenized/tokenizado)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKdHUg2D3O7h"
      },
      "source": [
        "def lemm_es(txx=[]):\n",
        "  '''\n",
        "  txx is a list or tokenized text\n",
        "  retunrs: lemmatized words.\n",
        "  '''\n",
        "  lemm_text = []\n",
        "  for w in txx:\n",
        "    lemm_text.append(nlp(w)[0].lemma_)\n",
        "  return lemm_text"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SU8f6H6-CKnQ"
      },
      "source": [
        "Apliquemos el lemmatizer a nuestro texto corregido, y sin stopwords."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RsBRAdN31Mg",
        "outputId": "9105f6e0-96af-43cf-e544-8cec7588ba0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "lemm_text = lemm_es(short_text)\n",
        "\n",
        "print_text(short_text, module=11)\n",
        "print_text(lemm_text, module=11)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hola nombre Mario . Mi cuenta github umami . Estas listo \n",
            "convertirte experto LP . Esta horacio contiene errores gramaticales . \n",
            " ------- Tamano del texto:  21\n",
            "\n",
            "Hola nombrar Mario . Mi contar github umami . Estas listar \n",
            "convertirte experto LP . Esta horacio contener error gramatical . \n",
            " ------- Tamano del texto:  21\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPkhAoiaCPX8"
      },
      "source": [
        "## VI. Tag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiqzAWi-Ciu8"
      },
      "source": [
        "def pos_es(txx=[]):\n",
        "  '''\n",
        "  txx is a list or tokenized text\n",
        "  retunrs: lemmatized words.\n",
        "  '''\n",
        "  pos_text = []\n",
        "  for w in txx:\n",
        "    pos_text.append(nlp(w)[0].pos_)\n",
        "  return pos_text"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7c95BpbCrfZ",
        "outputId": "1775184d-8e01-4ca7-c727-d02dad4d92ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "pos_text = pos_es(short_text)\n",
        "\n",
        "print_text(short_text, module=11)\n",
        "print_text(pos_text, module=11)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hola nombre Mario . Mi cuenta github umami . Estas listo \n",
            "convertirte experto LP . Esta horacio contiene errores gramaticales . \n",
            " ------- Tamano del texto:  21\n",
            "\n",
            "PROPN NOUN PROPN PUNCT DET VERB PROPN PROPN PUNCT PRON ADJ \n",
            "PROPN ADJ NOUN PUNCT PRON ADV VERB NOUN ADJ PUNCT \n",
            " ------- Tamano del texto:  21\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0Yy2b_gOoA3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3Caoz2DOf-f"
      },
      "source": [
        "# Bag of Words (Bolsa de Palabras)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXF0I5m6OkQ8"
      },
      "source": [
        "https://es.wikipedia.org/wiki/Modelo_bolsa_de_palabras "
      ]
    }
  ]
}