{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_Procesamiento_del_Lenguaje_Natural.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJc9LP/meauN7g9FOA/4N+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IEXE-Tec/aprendizaje-maquina-2/blob/master/07_Procesamiento_del_Lenguaje_Natural.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kECscepGtsRT"
      },
      "source": [
        "Installing pycaret library:\n",
        "+ https://towardsdatascience.com/announcing-pycaret-2-0-39c11014540e \n",
        "+ https://pycaret.org/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_4YZ-A-ty8L"
      },
      "source": [
        "!pip install pycaret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUw9jGQ6e8zi",
        "outputId": "d7685e23-942c-4553-9c24-437803260179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "from pycaret.utils import version\n",
        "version()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.1.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA99ILJFHqa3"
      },
      "source": [
        "Installing Autocorrect:\n",
        "+ https://github.com/phatpiglet/autocorrect\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX_UZpHaHtYN",
        "outputId": "3c7bdae7-699f-47a5-e224-1371047e8cff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "!pip install autocorrect"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspellchecker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/96/827c132397d0eb5731c1eda05dbfb019ede064ca8c7d0f329160ce0a4acd/pyspellchecker-0.5.5-py2.py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.5.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i2Pou3JHZ4l"
      },
      "source": [
        "import nltk\n",
        "import pycaret\n",
        "from spellchecker import SpellChecker"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB2bZLB4umXm"
      },
      "source": [
        "# Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPdVrOSDup0Q"
      },
      "source": [
        "## I. Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBGITeID1qQL"
      },
      "source": [
        "# importar el modulo de tokenizacion de nltk\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWoV0d8x2qAF",
        "outputId": "7b61f488-5e0e-430a-a921-5ee1e77d785f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "example_text = \"Esto es un ejemplo. O noooo?\"\n",
        "print(sent_tokenize(example_text))\n",
        "print(word_tokenize(example_text))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Esto es un ejemplo.', 'O noooo?']\n",
            "['Esto', 'es', 'un', 'ejemplo', '.', 'O', 'noooo', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dSxot7HuuWo",
        "outputId": "601e795f-f906-478a-8e73-4b0abbd2cf91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "# Texto de ejemplo. Ene ste caso usamos las tres comillas para separar\n",
        "# el texto en varias lineas dentro de nuestro codigo.\n",
        "example_text = ''' Hola mi nombre es Mario. Mi cuenta de github\n",
        "es uumami. Estas listo para convertirte en un experto de NLP.\n",
        "Ezta horacion contiene muchos erroress gramaticales.\n",
        "'''\n",
        "print(example_text)\n",
        "print(sent_tokenize(example_text))\n",
        "print(word_tokenize(example_text))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Hola mi nombre es Mario. Mi cuenta de github\n",
            "es uumami. Estas listo para convertirte en un experto de NLP.\n",
            "Ezta horacion contiene muchos erroress gramaticales.\n",
            "\n",
            "[' Hola mi nombre es Mario.', 'Mi cuenta de github\\nes uumami.', 'Estas listo para convertirte en un experto de NLP.', 'Ezta horacion contiene muchos erroress gramaticales.']\n",
            "['Hola', 'mi', 'nombre', 'es', 'Mario', '.', 'Mi', 'cuenta', 'de', 'github', 'es', 'uumami', '.', 'Estas', 'listo', 'para', 'convertirte', 'en', 'un', 'experto', 'de', 'NLP', '.', 'Ezta', 'horacion', 'contiene', 'muchos', 'erroress', 'gramaticales', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tj0dRqdGOSf"
      },
      "source": [
        "texto = word_tokenize(example_text)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBTNkxBxIa5o"
      },
      "source": [
        "# II. Spell check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lxqzZ_oRs2_"
      },
      "source": [
        "from autocorrect import Speller"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_Yb6k0GIfi4"
      },
      "source": [
        "spell = Speller(lang='es')"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if_n9aZ8Iitl",
        "outputId": "57f35a5d-26af-41a7-a836-bbd4e22e9163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        }
      },
      "source": [
        "corrected_text = [spell(i) for i in texto]\n",
        "corrected_text"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hola',\n",
              " 'mi',\n",
              " 'nombre',\n",
              " 'es',\n",
              " 'Mario',\n",
              " '.',\n",
              " 'Mi',\n",
              " 'cuenta',\n",
              " 'de',\n",
              " 'github',\n",
              " 'es',\n",
              " 'umami',\n",
              " '.',\n",
              " 'Estas',\n",
              " 'listo',\n",
              " 'para',\n",
              " 'convertirte',\n",
              " 'en',\n",
              " 'un',\n",
              " 'experto',\n",
              " 'de',\n",
              " 'LP',\n",
              " '.',\n",
              " 'Esta',\n",
              " 'horacio',\n",
              " 'contiene',\n",
              " 'muchos',\n",
              " 'errores',\n",
              " 'gramaticales',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVw9RFFEP9l-"
      },
      "source": [
        "## III. Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZAzvIOnRmYG"
      },
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjjDE2POQ2H8",
        "outputId": "2d82a145-aacb-4262-ae1e-8aa9a4517835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "stopwords_en = stopwords.words('english')\n",
        "\n",
        "counter = 0\n",
        "for w in stopwords_en:\n",
        "  print(w, end=', ')\n",
        "  counter += 1\n",
        "  if (counter%10)== 0:\n",
        "    print()\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i, me, my, myself, we, our, ours, ourselves, you, you're, \n",
            "you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, \n",
            "himself, she, she's, her, hers, herself, it, it's, its, itself, \n",
            "they, them, their, theirs, themselves, what, which, who, whom, this, \n",
            "that, that'll, these, those, am, is, are, was, were, be, \n",
            "been, being, have, has, had, having, do, does, did, doing, \n",
            "a, an, the, and, but, if, or, because, as, until, \n",
            "while, of, at, by, for, with, about, against, between, into, \n",
            "through, during, before, after, above, below, to, from, up, down, \n",
            "in, out, on, off, over, under, again, further, then, once, \n",
            "here, there, when, where, why, how, all, any, both, each, \n",
            "few, more, most, other, some, such, no, nor, not, only, \n",
            "own, same, so, than, too, very, s, t, can, will, \n",
            "just, don, don't, should, should've, now, d, ll, m, o, \n",
            "re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, \n",
            "doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, \n",
            "ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, \n",
            "shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't, "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc2il63oQB4q",
        "outputId": "137a1c2e-77e3-4752-dcd8-46e18b7e32cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        }
      },
      "source": [
        "stopwords_es = stopwords.words('spanish')\n",
        "\n",
        "counter = 0\n",
        "for w in stopwords_es:\n",
        "  print(w, end=', ')\n",
        "  counter += 1\n",
        "  if (counter%10)== 0:\n",
        "    print()\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "de, la, que, el, en, y, a, los, del, se, \n",
            "las, por, un, para, con, no, una, su, al, lo, \n",
            "como, más, pero, sus, le, ya, o, este, sí, porque, \n",
            "esta, entre, cuando, muy, sin, sobre, también, me, hasta, hay, \n",
            "donde, quien, desde, todo, nos, durante, todos, uno, les, ni, \n",
            "contra, otros, ese, eso, ante, ellos, e, esto, mí, antes, \n",
            "algunos, qué, unos, yo, otro, otras, otra, él, tanto, esa, \n",
            "estos, mucho, quienes, nada, muchos, cual, poco, ella, estar, estas, \n",
            "algunas, algo, nosotros, mi, mis, tú, te, ti, tu, tus, \n",
            "ellas, nosotras, vosotros, vosotras, os, mío, mía, míos, mías, tuyo, \n",
            "tuya, tuyos, tuyas, suyo, suya, suyos, suyas, nuestro, nuestra, nuestros, \n",
            "nuestras, vuestro, vuestra, vuestros, vuestras, esos, esas, estoy, estás, está, \n",
            "estamos, estáis, están, esté, estés, estemos, estéis, estén, estaré, estarás, \n",
            "estará, estaremos, estaréis, estarán, estaría, estarías, estaríamos, estaríais, estarían, estaba, \n",
            "estabas, estábamos, estabais, estaban, estuve, estuviste, estuvo, estuvimos, estuvisteis, estuvieron, \n",
            "estuviera, estuvieras, estuviéramos, estuvierais, estuvieran, estuviese, estuvieses, estuviésemos, estuvieseis, estuviesen, \n",
            "estando, estado, estada, estados, estadas, estad, he, has, ha, hemos, \n",
            "habéis, han, haya, hayas, hayamos, hayáis, hayan, habré, habrás, habrá, \n",
            "habremos, habréis, habrán, habría, habrías, habríamos, habríais, habrían, había, habías, \n",
            "habíamos, habíais, habían, hube, hubiste, hubo, hubimos, hubisteis, hubieron, hubiera, \n",
            "hubieras, hubiéramos, hubierais, hubieran, hubiese, hubieses, hubiésemos, hubieseis, hubiesen, habiendo, \n",
            "habido, habida, habidos, habidas, soy, eres, es, somos, sois, son, \n",
            "sea, seas, seamos, seáis, sean, seré, serás, será, seremos, seréis, \n",
            "serán, sería, serías, seríamos, seríais, serían, era, eras, éramos, erais, \n",
            "eran, fui, fuiste, fue, fuimos, fuisteis, fueron, fuera, fueras, fuéramos, \n",
            "fuerais, fueran, fuese, fueses, fuésemos, fueseis, fuesen, sintiendo, sentido, sentida, \n",
            "sentidos, sentidas, siente, sentid, tengo, tienes, tiene, tenemos, tenéis, tienen, \n",
            "tenga, tengas, tengamos, tengáis, tengan, tendré, tendrás, tendrá, tendremos, tendréis, \n",
            "tendrán, tendría, tendrías, tendríamos, tendríais, tendrían, tenía, tenías, teníamos, teníais, \n",
            "tenían, tuve, tuviste, tuvo, tuvimos, tuvisteis, tuvieron, tuviera, tuvieras, tuviéramos, \n",
            "tuvierais, tuvieran, tuviese, tuvieses, tuviésemos, tuvieseis, tuviesen, teniendo, tenido, tenida, \n",
            "tenidos, tenidas, tened, "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kw4_Nz3UmJm"
      },
      "source": [
        "def print_text(texx = [], module=10, sep=' '):\n",
        "  counter = 0\n",
        "  for w in texx:\n",
        "    print(w, end=sep)\n",
        "    counter += 1\n",
        "    if (counter % module)== 0:\n",
        "      print()\n",
        "  print('\\n ------- Tamano del texto: ', len(texx))\n",
        "  print()"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITCTj4EFULL-",
        "outputId": "530e2b1f-c27b-4c99-bda7-c85e25811009",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "# Removamos las stopwords de nuestro texto\n",
        "print('\\n Texto corregido:')\n",
        "print_text(corrected_text, module=11)\n",
        "\n",
        "short_text = [w for w in corrected_text if w not in stopwords_es]\n",
        "print('\\n Texto sin stopwords:')\n",
        "print_text(short_text, module=11)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Texto corregido:\n",
            "Hola mi nombre es Mario . Mi cuenta de github es \n",
            "umami . Estas listo para convertirte en un experto de LP \n",
            ". Esta horacio contiene muchos errores gramaticales . \n",
            " ------- Tamano del texto:  30\n",
            "\n",
            "\n",
            " Texto sin stopwords:\n",
            "Hola nombre Mario . Mi cuenta github umami . Estas listo \n",
            "convertirte experto LP . Esta horacio contiene errores gramaticales . \n",
            " ------- Tamano del texto:  21\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzxM8D-HEvA-"
      },
      "source": [
        "## IV. Stemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqzc2xAj8uyt"
      },
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "stemmer = SnowballStemmer('spanish')"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNd5c-nyMJ1W",
        "outputId": "7afb9ecc-bcac-4bd5-cca6-6e6aabd2eb7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "[stemmer.stem(i) for i in ['corriendo', 'correr', 'corremos',\n",
        "                           'corriamos','corrian', \n",
        "                           'correlacion', 'correlacionado']]"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['corr', 'corr', 'corr', 'corri', 'corri', 'correlacion', 'correlacion']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0srEErAF0Nv",
        "outputId": "24075baa-7fab-4eab-d020-35abd2134816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        }
      },
      "source": [
        "stemmed_text = [stemmer.stem(i) for i in corrected_text]\n",
        "stemmed_text"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hol',\n",
              " 'mi',\n",
              " 'nombr',\n",
              " 'es',\n",
              " 'mari',\n",
              " '.',\n",
              " 'mi',\n",
              " 'cuent',\n",
              " 'de',\n",
              " 'github',\n",
              " 'es',\n",
              " 'umami',\n",
              " '.',\n",
              " 'estas',\n",
              " 'list',\n",
              " 'par',\n",
              " 'convertirt',\n",
              " 'en',\n",
              " 'un',\n",
              " 'expert',\n",
              " 'de',\n",
              " 'lp',\n",
              " '.',\n",
              " 'esta',\n",
              " 'horaci',\n",
              " 'contien',\n",
              " 'much',\n",
              " 'error',\n",
              " 'gramatical',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    }
  ]
}